<!DOCTYPE html><html data-bs-theme="light" lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no"><title>Stable-V2A - Synchronized Sound Effects Synthesis</title><meta name="description" content="Stable-V2A is a two-stage model for synthesizing synchronized sound effects with support for temporal and semantic controls 
"><link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css?h=a549af2a81cd9900ee897d8bc9c4b5e9"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Albert+Sans&amp;display=swap"><link rel="stylesheet" href="assets/css/styles.min.css?h=21de4534873f620351b44eae2078d7ea"><link rel="stylesheet" type="text/css" href="spectrogram-player/style.css" />
<script type="text/javascript" src="spectrogram-player/spectrogram-player.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.3.2/lazysizes.min.js"></script>
</head><body><div class="container-fluid"><div class="row"><div class="col-12 d-xxl-flex align-items-xxl-center"><div class="centered-div" style="width: 100%;margin-bottom: 0.5rem;margin-top: 0.5rem;"><div class="centered-div" style="background: #ffffff;border-radius: 34px;width: 100%;"><div class="margin-desktop" style="padding: 1rem;border-radius: 12px;max-width: 900px;margin-bottom: 2rem;border-bottom-width: 4px;border-bottom-color: var(--bs-primary);"><h1 style="text-align: center;margin-top: 0.5rem;color: var(--bs-link-hover-color);margin-bottom: 0.1rem;letter-spacing: 0.2px;font-family: 'Albert Sans', sans-serif;"><strong>Stable-V2A</strong></h1><h2 style="text-align: center;color: var(--bs-link-hover-color);margin-bottom: 1.7rem;letter-spacing: 0.2px;font-family: 'Albert Sans', sans-serif;"><strong>Synthesis of Synchronized Audio Effects with Temporal and Semantic Controls</strong></h2><p style="margin-bottom: 24px;text-align: center;font-style: italic;font-size: 21px;color: #000000;font-family: 'Albert Sans', sans-serif;"><span style="font-style: normal !important;">Riccardo F. Gramaccioni </span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-diamond-fill" style="font-size: 15px;color: #000000;">
  <path d="M2.45 7.4 7.2 1.067a1 1 0 0 1 1.6 0L13.55 7.4a1 1 0 0 1 0 1.2L8.8 14.933a1 1 0 0 1-1.6 0L2.45 8.6a1 1 0 0 1 0-1.2z"></path>
</svg><span style="font-style: normal !important;">, Christian Marinoni&nbsp;</span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-diamond-fill" style="font-size: 15px;color: #000000;">
  <path d="M2.45 7.4 7.2 1.067a1 1 0 0 1 1.6 0L13.55 7.4a1 1 0 0 1 0 1.2L8.8 14.933a1 1 0 0 1-1.6 0L2.45 8.6a1 1 0 0 1 0-1.2z"></path>
</svg><span style="font-style: normal !important;">, Emilian Postolache </span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-spade-fill" style="font-size: 15px;color: #000000;">
  <path d="M7.184 11.246A3.5 3.5 0 0 1 1 9c0-1.602 1.14-2.633 2.66-4.008C4.986 3.792 6.602 2.33 8 0c1.398 2.33 3.014 3.792 4.34 4.992C13.86 6.367 15 7.398 15 9a3.5 3.5 0 0 1-6.184 2.246 19.92 19.92 0 0 0 1.582 2.907c.231.35-.02.847-.438.847H6.04c-.419 0-.67-.497-.438-.847a19.919 19.919 0 0 0 1.582-2.907"></path>
</svg><span style="font-style: normal !important;">, Marco Comunit√†&nbsp;</span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-club-fill" style="font-size: 15px;color: #000000;">
  <path d="M11.5 12.5a3.493 3.493 0 0 1-2.684-1.254 19.92 19.92 0 0 0 1.582 2.907c.231.35-.02.847-.438.847H6.04c-.419 0-.67-.497-.438-.847a19.919 19.919 0 0 0 1.582-2.907 3.5 3.5 0 1 1-2.538-5.743 3.5 3.5 0 1 1 6.708 0A3.5 3.5 0 1 1 11.5 12.5"></path>
</svg><span style="font-style: normal !important;">, Luca Cosmo </span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-spade-fill" style="font-size: 15px;color: #000000;">
  <path d="M7.184 11.246A3.5 3.5 0 0 1 1 9c0-1.602 1.14-2.633 2.66-4.008C4.986 3.792 6.602 2.33 8 0c1.398 2.33 3.014 3.792 4.34 4.992C13.86 6.367 15 7.398 15 9a3.5 3.5 0 0 1-6.184 2.246 19.92 19.92 0 0 0 1.582 2.907c.231.35-.02.847-.438.847H6.04c-.419 0-.67-.497-.438-.847a19.919 19.919 0 0 0 1.582-2.907"></path>
</svg><span style="font-style: normal !important;">, Joshua D. Reiss&nbsp;</span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-club-fill" style="font-size: 15px;color: #000000;">
  <path d="M11.5 12.5a3.493 3.493 0 0 1-2.684-1.254 19.92 19.92 0 0 0 1.582 2.907c.231.35-.02.847-.438.847H6.04c-.419 0-.67-.497-.438-.847a19.919 19.919 0 0 0 1.582-2.907 3.5 3.5 0 1 1-2.538-5.743 3.5 3.5 0 1 1 6.708 0A3.5 3.5 0 1 1 11.5 12.5"></path>
</svg><span style="font-style: normal !important;">, and Danilo Comminiello&nbsp;</span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-diamond-fill" style="font-size: 15px;color: #000000;">
  <path d="M2.45 7.4 7.2 1.067a1 1 0 0 1 1.6 0L13.55 7.4a1 1 0 0 1 0 1.2L8.8 14.933a1 1 0 0 1-1.6 0L2.45 8.6a1 1 0 0 1 0-1.2z"></path>
</svg></p><p style="text-align: center;font-size: 17px;color: var(--bs-light-text-emphasis);font-family: 'Albert Sans', sans-serif;"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-diamond-fill" style="font-size: 15px;color: var(--bs-light-text-emphasis);">
  <path d="M2.45 7.4 7.2 1.067a1 1 0 0 1 1.6 0L13.55 7.4a1 1 0 0 1 0 1.2L8.8 14.933a1 1 0 0 1-1.6 0L2.45 8.6a1 1 0 0 1 0-1.2z"></path>
</svg>&nbsp;Sapienza University of Rome, Italy<br><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-club-fill" style="font-size: 15px;color: var(--bs-light-text-emphasis);">
  <path d="M11.5 12.5a3.493 3.493 0 0 1-2.684-1.254 19.92 19.92 0 0 0 1.582 2.907c.231.35-.02.847-.438.847H6.04c-.419 0-.67-.497-.438-.847a19.919 19.919 0 0 0 1.582-2.907 3.5 3.5 0 1 1-2.538-5.743 3.5 3.5 0 1 1 6.708 0A3.5 3.5 0 1 1 11.5 12.5"></path>
</svg>&nbsp;Queen Mary University of London, UK<br><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-suit-spade-fill" style="font-size: 15px;color: var(--bs-light-text-emphasis);">
  <path d="M7.184 11.246A3.5 3.5 0 0 1 1 9c0-1.602 1.14-2.633 2.66-4.008C4.986 3.792 6.602 2.33 8 0c1.398 2.33 3.014 3.792 4.34 4.992C13.86 6.367 15 7.398 15 9a3.5 3.5 0 0 1-6.184 2.246 19.92 19.92 0 0 0 1.582 2.907c.231.35-.02.847-.438.847H6.04c-.419 0-.67-.497-.438-.847a19.919 19.919 0 0 0 1.582-2.907"></path>
</svg>&nbsp;Ca' Foscari University of Venice, Italy</p><div style="text-align: center;margin-bottom: 0.5rem;"><a class="btn btn-primary" role="button" style="border-radius: 35px;margin-right: 15px;background: var(--bs-btn-hover-bg);" rel="external" target="_blank"><img src="assets/img/arxiv_logo_full.png?h=8defb76aa3ddc04a594a334760c1bf84" width="60" height="27"></a><a class="btn btn-primary" role="button" style="border-radius: 35px;background: var(--bs-link-hover-color);" rel="external"><img src="assets/img/github.png?h=e144ccf9f9ba55ac681f0e92ec6b1a69" style="height: 27px;" width="27" height="27">&nbsp;Code (available soon)</a></div></div><div class="text-start d-flex justify-content-center" style="width: 100%;background: #f2f2f2;"><div style="padding: 20px;max-width: 700px;width: 100%;margin-top: 1rem;margin-bottom: 1rem;"><h3 style="color: var(--bs-link-hover-color);font-family: 'Albert Sans', sans-serif;"><strong>What's new?</strong></h3><ul class="fs-5" style="text-align: justify;"><li>A <strong>two-stage model</strong> consisting of: a <strong>RMS-Mapper</strong> that estimates the <strong>envelope </strong>given an input video; and <strong>Stable-Foley</strong>, a diffusion model that generates an audio semantically and temporally aligned with the target video.</li><li>Temporal alignment is guaranteed by the use of the envolope as an input to the <strong>ControlNet</strong>, while semantic alignment is achieved as cross-attention conditioning of the diffusion process.</li><li>We test our model on <strong><em>Greatest Hits</em> </strong>and we introduce a brand-new dataset named <strong><em>Walking The Maps</em></strong>.</li></ul></div></div></div></div></div></div></div><div class="container" style="margin-top: 4rem;"><div class="row"><div class="col-md-12" id="more" style="margin-bottom: 1.5rem;"><h3 class="h3-bigger" style="color: var(--bs-link-hover-color);font-family: 'Albert Sans', sans-serif;"><strong>Introduction</strong></h3><p class="fs-5" style="text-align: justify;">Sound designers and Foley artists usually sonorize a scene, such as from a movie or video game, by manually annotating and sonorizing each action of interest in the video.&nbsp;<br>In our case, the intent is to leave full creative control to sound designers with a tool that allows them to bypass the more repetitive parts of their work, thus being able to focus on the creative aspects of sound production.<br><br>We introduce a new two-stage model for Video-to-Audio (V2A) generation, <strong>Stable-V2A</strong>, where the two stages are represented by <strong>RMS-Mapper</strong> and <strong>Stable-Foley</strong>.<br><br><strong>RMS-Mapper</strong> is a simple but effective network for mapping an RMS envelope directly from a video; it takes representative features of frames and optical flow of videos as input.<br><br><strong>Stable-Foley</strong>, the model for synthesizing sound effects, relies on Stable Audio, a state-of-the-art latent diffusion model for audio generation, to obtain the final output. In order to take advantage of the prior knowledge of this model and guide its generation process via the RMS envelope, we leverage a <strong>ControlNet</strong>, which is a network used to control the diffusion process via extra conditioning.&nbsp;</p><div style="padding: 20px;width: 100%;text-align: center;"><img src="assets/img/schema-prima-pagina-biggertext3.jpg?h=9adb883dcae69349c239701ad1d46796" style="width: 100%;max-width: 1205px;"></div><p class="fs-5" style="text-align: justify;">We train and test our model on <strong><em>Greatest Hits</em></strong>, a dataset commonly used to evaluate V2A models. In addition, to test our model on a case study of interest, we introduce in this paper a dataset of videos extracted from video games depicting animated characters walking in different locations, called <strong><em>Walking The Maps</em></strong>.</p></div></div></div><div class="container"><div class="row d-md-flex d-xl-flex justify-content-md-center justify-content-xl-center" style="margin-bottom: 3rem;"><div class="col-md-9 col-lg-8 col-xl-7 col-xxl-6 offset-xxl-0 d-xxl-flex align-items-xxl-center"><figure class="figure"><img class="img-fluid figure-img" src="assets/img/esempio-prima-pagina.jpg?h=72c61cd8300ec83b61196b450393f0a0"></figure></div></div></div><div class="container"><h3 class="h3-bigger"><strong>How it works</strong></h3><p class="fs-5" style="text-align: justify;">Stable-V2A is able to generate audios that are semantically and temporally aligned to videos.</p><p class="fs-5" style="text-align: justify;">It all starts from a <strong>silent video</strong>, which represents the input to our model.</p><div class="row d-md-flex d-xl-flex justify-content-md-center justify-content-xl-center" style="margin-bottom: 1rem;"><div class="col-md-9 col-lg-8 col-xl-7 col-xxl-6 offset-xxl-0 d-xxl-flex justify-content-xxl-center align-items-xxl-center position-relative" style="width: 425px;max-width: 100%;"><video class="custom-video" preload="auto" loop="" autoplay="" style="max-width: 100%;"><source src="https://www.l3das.com/assets/extra/input_silent.mp4" type="video/mp4"></video><button class="btn btn-dark play-button position-absolute top-50 start-50 translate-middle d-none" type=""><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-play-fill">
  <path d="m11.596 8.697-6.363 3.692c-.54.313-1.233-.066-1.233-.697V4.308c0-.63.692-1.01 1.233-.696l6.363 3.692a.802.802 0 0 1 0 1.393z"></path>
</svg></button></div></div><div class="row"><div class="col-md-6"><p class="fs-5" style="text-align: justify;">In Stage 1, <strong>RMS-Mapper</strong> generates an evelope from the frames and optical flow embeddings passed as input (and extracted via <strong>TC-CLIP</strong>).</p><div class="row d-md-flex d-xl-flex justify-content-md-center justify-content-xl-center" style="margin-bottom: 3rem;"><div class="col-md-9 col-lg-8 col-xl-7 col-xxl-9 offset-xxl-0 d-xxl-flex justify-content-xxl-center align-items-xxl-center" style="text-align: center;"><figure class="figure" style="text-align: center;"><img class="img-fluid figure-img" src="assets/img/rms-mapper-3.png?h=b64e3ae492833df3ff639666916cdbf8" width="547" height="506"></figure></div></div></div><div class="col-md-6"><p class="fs-5" style="text-align: justify;">In Stage 2,&nbsp;<strong>Stable-Foley</strong>&nbsp;generates the output audio. Here the semantics is specified by cross-conditioning the latent diffusion model with a latent representation of an audio sample or a text prompt. Moreover, in order to control the process with the RMS envelope estimated in Stage 1, we use a <strong>ControlNet</strong>.&nbsp;</p><div class="row d-md-flex d-xl-flex justify-content-md-center justify-content-xl-center" style="margin-bottom: 3rem;"><div class="col-md-9 col-lg-8 col-xl-7 col-xxl-6 offset-xxl-0 d-xxl-flex justify-content-xxl-center align-items-xxl-center" style="text-align: center;width: 492px;"><figure class="figure" style="text-align: center;"><img class="img-fluid figure-img" src="assets/img/stable-foley.png?h=58d7630d9976db6751d5560c97bd825e" width="500" height="300"></figure></div></div></div></div><p class="fs-5" style="text-align: justify;">In the case of the silent video above, we generated 2-sec chunks and we concatenated them to get the full track. The result is here proposed:</p><div class="row d-md-flex d-xl-flex justify-content-md-center justify-content-xl-center" style="margin-bottom: 3rem;max-height: 100%;"><div class="col-md-9 col-lg-8 col-xl-7 col-xxl-8 offset-xxl-0 d-xxl-flex justify-content-xxl-center align-items-xxl-center position-relative" style="width: 950px;max-width: 100%;"><video class="custom-video" preload="auto"><source src="https://www.l3das.com/assets/extra/output_example1.mp4" type="video/mp4"></video><button class="btn btn-dark play-button position-absolute top-50 start-50 translate-middle d-none" type=""><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-play-fill">
  <path d="m11.596 8.697-6.363 3.692c-.54.313-1.233-.066-1.233-.697V4.308c0-.63.692-1.01 1.233-.696l6.363 3.692a.802.802 0 0 1 0 1.393z"></path>
</svg></button></div></div><h3 class="h3-bigger"><strong>Examples</strong></h3><p class="fs-5" style="text-align: justify;">Here we propose some examples to appreciate the results obtained by our method and baselines.<br><br>You can listen to selected samples generated from audio&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-soundwave" data-toggle="tooltip" data-placement="top" title="Audio prompt" style="width: 30px;height: 30px;">
  <path fill-rule="evenodd" d="M8.5 2a.5.5 0 0 1 .5.5v11a.5.5 0 0 1-1 0v-11a.5.5 0 0 1 .5-.5m-2 2a.5.5 0 0 1 .5.5v7a.5.5 0 0 1-1 0v-7a.5.5 0 0 1 .5-.5m4 0a.5.5 0 0 1 .5.5v7a.5.5 0 0 1-1 0v-7a.5.5 0 0 1 .5-.5m-6 1.5A.5.5 0 0 1 5 6v4a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m8 0a.5.5 0 0 1 .5.5v4a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m-10 1A.5.5 0 0 1 3 7v2a.5.5 0 0 1-1 0V7a.5.5 0 0 1 .5-.5m12 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0V7a.5.5 0 0 1 .5-.5"></path>
</svg> and text prompts <svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-card-text" data-toggle="tooltip" data-placement="top" title="Text prompt" style="width: 26px;height: 26px;">
  <path d="M14.5 3a.5.5 0 0 1 .5.5v9a.5.5 0 0 1-.5.5h-13a.5.5 0 0 1-.5-.5v-9a.5.5 0 0 1 .5-.5zm-13-1A1.5 1.5 0 0 0 0 3.5v9A1.5 1.5 0 0 0 1.5 14h13a1.5 1.5 0 0 0 1.5-1.5v-9A1.5 1.5 0 0 0 14.5 2z"></path>
  <path d="M3 5.5a.5.5 0 0 1 .5-.5h9a.5.5 0 0 1 0 1h-9a.5.5 0 0 1-.5-.5M3 8a.5.5 0 0 1 .5-.5h9a.5.5 0 0 1 0 1h-9A.5.5 0 0 1 3 8m0 2.5a.5.5 0 0 1 .5-.5h6a.5.5 0 0 1 0 1h-6a.5.5 0 0 1-.5-.5"></path>
</svg>&nbsp;by expanding the corresponding sections.</p><h4 class="h4-bigger" style="margin-top: 3.5rem;"><strong>Greatest Hits</strong></h4><p class="fs-5" style="text-align: justify;">We use the <strong><em>Greatest Hits</em></strong> dataset, a widely-adopted datasets for V2A tasks.<br>This dataset includes videos of humans using a drumstick to hit or rub objects or surfaces.</p></div><div class="container" style="margin-bottom: 2.5rem;border-style: dashed;border-color: #4c515580;border-radius: 16px;margin-top: 1.5rem;"><div class="row"><div class="col-md-12" style="margin-bottom: 1rem;"><p class="fs-5 d-flex justify-content-between align-items-center example-selector-container" style="margin-top: 1rem;margin-bottom: 0rem;border-radius: 16px;text-align: center;padding: 8px;"><span class="d-flex align-items-center"><strong>Example</strong><select style="width: 36px;" data-example-gallery="video-gallery-1" data-gallery-type="DEFAULT"><option value="1" selected="">1</option><option value="2">2</option><option value="3">3</option><option value="4">4</option><option value="5">5</option><option value="6">6</option></select><strong>&nbsp;&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-soundwave" data-toggle="tooltip" data-placement="top" title="Audio prompt" style="width: 30px;height: 30px;">
  <path fill-rule="evenodd" d="M8.5 2a.5.5 0 0 1 .5.5v11a.5.5 0 0 1-1 0v-11a.5.5 0 0 1 .5-.5m-2 2a.5.5 0 0 1 .5.5v7a.5.5 0 0 1-1 0v-7a.5.5 0 0 1 .5-.5m4 0a.5.5 0 0 1 .5.5v7a.5.5 0 0 1-1 0v-7a.5.5 0 0 1 .5-.5m-6 1.5A.5.5 0 0 1 5 6v4a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m8 0a.5.5 0 0 1 .5.5v4a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m-10 1A.5.5 0 0 1 3 7v2a.5.5 0 0 1-1 0V7a.5.5 0 0 1 .5-.5m12 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0V7a.5.5 0 0 1 .5-.5"></path>
</svg></strong></span><button class="btn btn-primary toggle-gallery-btn" type="button" data-bs-toggle="collapse" data-bs-target="#video-gallery-1-collapse" aria-expanded="false" style="background: var(--bs-link-hover-color);border-radius: 19px;min-width: 67px;">Show</button></p><div id="video-gallery-1-collapse" class="collapse video-gallery-collapse"><div id="video-gallery-1" class="video-gallery" style="margin-top: 15px;"></div></div></div></div></div><div class="container"><p class="fs-5" style="text-align: justify;">We&nbsp;also use CLAP as semantic conditioning meaning that we can use text as additional modality at inference time.</p></div><div class="container" style="margin-bottom: 2.5rem;border-style: dashed;border-color: #4c515580;border-radius: 16px;margin-top: 1.5rem;"><div class="row"><div class="col-md-12" style="margin-bottom: 1rem;"><p class="fs-5 d-flex justify-content-between align-items-center example-selector-container" style="margin-top: 1rem;margin-bottom: 0rem;border-radius: 16px;text-align: center;padding: 8px;"><span class="d-flex align-items-center"><strong>Example</strong><select style="width: 36px;" data-example-gallery="video-gallery-2" data-gallery-type="TEXT"><option value="1" selected="">1</option><option value="2">2</option><option value="3">3</option><option value="4">4</option><option value="5">5</option><option value="6">6</option></select><strong>&nbsp;&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-card-text" data-toggle="tooltip" data-placement="top" title="Text prompt" style="width: 26px;height: 26px;">
  <path d="M14.5 3a.5.5 0 0 1 .5.5v9a.5.5 0 0 1-.5.5h-13a.5.5 0 0 1-.5-.5v-9a.5.5 0 0 1 .5-.5zm-13-1A1.5 1.5 0 0 0 0 3.5v9A1.5 1.5 0 0 0 1.5 14h13a1.5 1.5 0 0 0 1.5-1.5v-9A1.5 1.5 0 0 0 14.5 2z"></path>
  <path d="M3 5.5a.5.5 0 0 1 .5-.5h9a.5.5 0 0 1 0 1h-9a.5.5 0 0 1-.5-.5M3 8a.5.5 0 0 1 .5-.5h9a.5.5 0 0 1 0 1h-9A.5.5 0 0 1 3 8m0 2.5a.5.5 0 0 1 .5-.5h6a.5.5 0 0 1 0 1h-6a.5.5 0 0 1-.5-.5"></path>
</svg>&nbsp;</strong></span><button class="btn btn-primary toggle-gallery-btn" type="button" data-bs-toggle="collapse" data-bs-target="#video-gallery-text-collapse" aria-expanded="false" style="background: var(--bs-link-hover-color);border-radius: 19px;min-width: 67px;">Show</button></p><div id="video-gallery-text-collapse" class="collapse video-gallery-collapse"><div id="video-gallery-2" class="video-gallery" style="margin-top: 15px;"></div></div></div></div></div><div class="container"><h4 class="h4-bigger" style="margin-top: 3.5rem;"><strong>Walking The Maps</strong></h4><p class="fs-5" style="text-align: justify;">In this work, we introduce a new dataset named <strong><em>Walking The Maps</em></strong> (WTM).<br><br>WTM includes short videos from gameplay sessions from YouTube of 4&nbsp;video games: Hogwarts Legacy, Zelda Breath of the Wild, Assassin's Creed: Odyssey, Assassin's Creed IV Black Flag.<br><br>For each video, we extracted only clips in which the sound of the steps is clearly audible and there are no other possible sound sources in the video that can be related to the target sound.</p><div class="row d-md-flex d-xl-flex justify-content-md-center justify-content-xl-center" style="margin-bottom: 3rem;"><div class="col-md-9 col-lg-8 col-xl-7 col-xxl-6 offset-xxl-0 d-xxl-flex align-items-xxl-center" style="max-width: 500px;"><figure class="figure"><img class="img-fluid figure-img" src="assets/img/wtm-sample-2.jpg?h=1b50000e95a91d693069d51f6093f243"></figure></div></div></div><div class="container" style="margin-bottom: 2.5rem;border-style: dashed;border-color: #4c515580;border-radius: 16px;margin-top: 1.5rem;"><div class="row"><div class="col-md-12" style="margin-bottom: 1rem;"><p class="fs-5 d-flex justify-content-between align-items-center example-selector-container" style="margin-top: 1rem;margin-bottom: 0rem;border-radius: 16px;text-align: center;padding: 8px;"><span class="d-flex align-items-center"><strong>Example</strong><select style="width: 36px;" data-example-gallery="video-gallery-3" data-gallery-type="WTM"><option value="1" selected="">1</option><option value="2">2</option><option value="3">3</option><option value="4">4</option><option value="5">5</option><option value="6">6</option></select><strong>&nbsp;&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-soundwave" data-toggle="tooltip" data-placement="top" title="Audio prompt" style="width: 26px;height: 26px;">
  <path fill-rule="evenodd" d="M8.5 2a.5.5 0 0 1 .5.5v11a.5.5 0 0 1-1 0v-11a.5.5 0 0 1 .5-.5m-2 2a.5.5 0 0 1 .5.5v7a.5.5 0 0 1-1 0v-7a.5.5 0 0 1 .5-.5m4 0a.5.5 0 0 1 .5.5v7a.5.5 0 0 1-1 0v-7a.5.5 0 0 1 .5-.5m-6 1.5A.5.5 0 0 1 5 6v4a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m8 0a.5.5 0 0 1 .5.5v4a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5m-10 1A.5.5 0 0 1 3 7v2a.5.5 0 0 1-1 0V7a.5.5 0 0 1 .5-.5m12 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0V7a.5.5 0 0 1 .5-.5"></path>
</svg>&nbsp;</strong></span><button class="btn btn-primary toggle-gallery-btn" type="button" data-bs-toggle="collapse" data-bs-target="#video-gallery-wtm-collapse" aria-expanded="false" style="background: var(--bs-link-hover-color);border-radius: 19px;min-width: 67px;">Show</button></p><div id="video-gallery-wtm-collapse" class="collapse video-gallery-collapse"><div id="video-gallery-3" class="video-gallery" style="margin-top: 15px;"></div></div></div></div></div><div class="container" style="margin-top: 5rem;"><h3 class="h3-bigger" style="color: var(--bs-link-hover-color);"><strong>Results</strong></h3><p class="fs-5">Results for <strong>Stable-V2A</strong> and comparison with other SOTA models on <strong><em>Greatest Hits</em></strong>.&nbsp;Table shows whether the model generates the output conditioned on an audio or text prompt; HRC stands for Human Readable Control and refers to the use of time-varying interpretable signals that sound designers can use to control the generation process (i.e., envelope or onsets). <br><br>Our model provides the best results, even in the setting of text conditioned generation.</p><div class="table-responsive tableres">
    <table class="table">
        <thead>
            <tr>
                <th class='right-separator-table blue-borders' style='background: #e4f0ff'><span>Model</span></th>
                <th class='right-separator-table blue-borders' style='text-align: center; background: #e4f0ff; !important;'>Audio</th>
                <th class='right-separator-table blue-borders' style='text-align: center; background: #e4f0ff; !important;'>Text</th>
                <th class='right-separator-table blue-borders' style='text-align: center; background: #e4f0ff; !important;'>HRC</th>
                <th class='right-separator-table blue-borders' style='text-align: center; background: #e4f0ff; !important;'>FAD-P ‚Üì</th>
                <th class='right-separator-table blue-borders' style='text-align: center; background: #e4f0ff; !important;'>FAD-C ‚Üì</th>
                <th class='right-separator-table blue-borders' style='text-align: center; background: #e4f0ff; !important;'>FAD-LC ‚Üì</th>
                <th class='blue-borders' style='text-align: center; background: #e4f0ff; !important;'>E-LI ‚Üì</th>
                <th class='blue-borders' style='text-align: center; background: #e4f0ff; !important;'>CLAP ‚Üë</th>
                <th class='blue-borders' style='text-align: center; background: #e4f0ff; !important;'>FAVD ‚Üì</th>
            </tr>
        </thead>
        <tbody>
            <tr style="border-bottom: 1px solid #999;">
                <td class='right-separator-table'>SpecVQGAN</td>
                <td style='text-align: center;'>‚ùå</td>
                <td style='text-align: center;'>‚ùå</td>
                <td class='right-separator-table' style='text-align: center;'>‚ùå</td>
                <td style='text-align: center;'>99.07</td>
                <td style='text-align: center;'>1001</td>
                <td style='text-align: center;'>0.7102</td>
                <td style='text-align: center;'>0.0427</td>
                <td style='text-align: center;'>0.1418</td>
                <td style='text-align: center;'>6.5136</td>
            </tr>
            <tr style="border-bottom: 1px solid #999;">
                <td class='right-separator-table'>Diff-Foley</td>
                <td style='text-align: center;'>‚ùå</td>
                <td style='text-align: center;'>‚ùå</td>
                <td class='right-separator-table' style='text-align: center;'>‚ùå</td>
                <td style='text-align: center;'>85.70</td>
                <td style='text-align: center;'>654</td>
                <td style='text-align: center;'>0.4690</td>
                <td style='text-align: center;'>0.0448</td>
                <td style='text-align: center;'>0.3733</td>
                <td style='text-align: center;'>4.6186</td>
            </tr>
            <tr style="border-bottom: 1px solid #999;">
                <td class='right-separator-table'>CondFoleyGen</td>
                <td style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'>‚ùå</td>
                <td class='right-separator-table' style='text-align: center;'>‚ùå</td>
                <td style='text-align: center;'>74.93</td>
                <td style='text-align: center;'>650</td>
                <td style='text-align: center;'>0.4883</td>
                <td style='text-align: center;'>0.0357</td>
                <td style='text-align: center;'>0.4879</td>
                <td style='text-align: center;'>6.4814</td>
            </tr>
            <tr>
                <td class='right-separator-table' rowspan="2" style="vertical-align: middle; border-bottom: 1px solid #999;">SyncFusion</td>
                <td style='text-align: center;'>‚ùå</td>
                <td style='text-align: center;'>‚úÖ</td>
                <td class='right-separator-table' style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'>35.64</td>
                <td style='text-align: center;'>591</td>
                <td style='text-align: center;'>0.4365</td>
                <td style='text-align: center;'>0.0231</td>
                <td style='text-align: center;'>0.5154</td>
                <td style='text-align: center;'>4.3020</td>
            </tr>
            <tr style="border-bottom: 1px solid #999;">
                <td style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'>‚ùå</td>
                <td class='right-separator-table' style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'>27.85</td>
                <td style='text-align: center;'>542</td>
                <td style='text-align: center;'>0.2793</td>
                <td style='text-align: center;'>0.0177</td>
                <td style='text-align: center;'>0.6621</td>
                <td style='text-align: center;'>3.2825</td>
            </tr>
            <tr>
                <td class='right-separator-table' rowspan="2" style="vertical-align: middle; border-bottom: 1px solid #999;">Video-Foley</td>
                <td style='text-align: center;'>‚ùå</td>
                <td style='text-align: center;'>‚úÖ</td>
                <td class='right-separator-table' style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'>67.04</td>
                <td style='text-align: center;'>644</td>
                <td style='text-align: center;'>0.4997</td>
                <td style='text-align: center;'>0.0242</td>
                <td style='text-align: center;'>0.3680</td>
                <td style='text-align: center;'>4.9106</td>
            </tr>
            <tr style="border-bottom: 1px solid #999;">
                <td style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'>‚ùå</td>
                <td class='right-separator-table' style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'>28.45</td>
                <td style='text-align: center;'>435</td>
                <td style='text-align: center;'>0.1671</td>
                <td style='text-align: center;'>0.0183</td>
                <td style='text-align: center;'>0.6779</td>
                <td style='text-align: center;'>2.2070</td>
            </tr>
            <tr>
                <td class='right-separator-table' rowspan="2" style="vertical-align: middle; border-bottom: 1px solid #999;"><b>Stable-V2A (Ours)</b></td>
                <td style='text-align: center;'>‚ùå</td>
                <td style='text-align: center;'>‚úÖ</td>
                <td class='right-separator-table' style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'>32.80</td>
                <td style='text-align: center;'>381</td>
                <td style='text-align: center;'>0.2516</td>
                <td style='text-align: center;'><b>0.0137</b></td>
                <td style='text-align: center;'>0.4806</td>
                <td style='text-align: center;'>3.9413</td>
            </tr>
            <tr style="border-bottom: 1px solid #999;">
                <td style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'>‚ùå</td>
                <td class='right-separator-table' style='text-align: center;'>‚úÖ</td>
                <td style='text-align: center;'><b>16.57</b></td>
                <td style='text-align: center;'><b>217</b></td>
                <td style='text-align: center;'><b>0.1048</b></td>
                <td style='text-align: center;'><b>0.0137</b></td>
                <td style='text-align: center;'><b>0.6833</b></td>
                <td style='text-align: center;'><b>2.0264</b></td>
            </tr>
        </tbody>
    </table>
</div>
</div><div class="container" style="margin-top: 2rem;"><h2 class="h3-bigger"><strong>Cite us</strong></h2><p class="fs-5">If you found this work useful, please cite us as follows:</p><p class="font-monospace fs-6">@article{<br>}</p></div><footer class="text-center"><div class="container text-muted py-4 py-lg-5"><ul class="list-inline"><li class="list-inline-item me-4"><a class="link-secondary">Paper on arXiv</a></li><li class="list-inline-item me-4"><a class="link-secondary" href="#">Code on GitHub (available soon)</a></li><li class="list-inline-item"><a class="link-secondary" href="https://sites.google.com/uniroma1.it/ispamm/" data-bs-target="https://sites.google.com/uniroma1.it/ispamm/">ISPAMM Lab</a></li></ul><ul class="list-inline"><li class="list-inline-item me-4"><a href="https://twitter.com/IspammL"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-twitter-x" style="font-size: 15px;color: var(--bs-highlight-color);">
  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"></path>
</svg></a></li></ul></div></footer><script src="assets/js/jquery.min.js?h=6bcc3684f18aa21874fa709f122723cf"></script><script src="assets/bootstrap/js/bootstrap.min.js?h=374d178d651fa0eaf680a1fa7b40c788"></script><script src="assets/js/script.min.js?h=282f8a17fb4680e30e29b06b90312808"></script></body></html>